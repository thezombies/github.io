# 아는 것이 무엇인가?


1. 데이터 불러오기

> 개발환경 만들기
  >>  pd.options.display.max_columns = 
  >>  pd.options.display.max_rows = 
  
> 데이터 불러오기 (특정 컬럼만 불러오기)
> 인덱스 지정하기
  > df.set_index('')
  > df.reset_index('')
  
> 톺아보기
  


2. 데이터 정제하기

> 컬럼명 바꾸기
  >> df.rename({'a':'b'), axis = 'columns')
  >> df.columns = df.columns.str.replace('','')
  
  
> 데이터타입 바꾸기
> 결측치처리 
  >> def > apply 하는데, np에서, np.nan / np.fillna() / np.fillna(0)
  change all
  >> df['col_new'] = df['col'].replace('a',np.nan)
  
  case by case
  >> df.loc[df['col'] > 0,"target_col"] = np.nan
  
  
  


> apply로 문자형 바꾸기
  >> def if a == '' : return '' > apply 
  
> apply로 연산 적용하기
  >> 데이터를 분류하기 (ref. CASE WHEN)

> apply for many x by using lambda
  >> def sample(x,y):
      return x+y
      
     df['new'] = df.apply(lambda x : sample(df["x"]i, df["y"]), axis =1) # pandas에서 axis = 0은 index, 1은 column내 values 즉 series를 뜻한다.

  >> lambda는 필터로도 기능한다
      e.g. df['sample'] = df.apply(lambda x : return Z if x is none, axis = 1)

> dataframe에서 null을 비교하는 걸 isnull()이라고 한다면,
  >> value에서의 nan을 판별하는 건, x != x였다...(is None이기도 하는데, 결국 apply에서는 적용되지 못했다)
  >> 방법은 replace(np.nan, -1) 로 하고, -1을 이용해 함수를 만들고 > apply를 하는 것.
  >> 요 간단한 것 때문에, 몇 시간을 잡아먹었는지.......ㅠㅠ
  
  >> 그리고 해설에서는...pd.isnull(df["Age(clean)']) 으로 해서, True / False를 판단하는 것이었다....


> dataframe에서 between은
  >> vlaue 에서는 10 <= value < 12 이다
  
  def invalid(status, height, initial_weight, lowest_weight, target_weight, BMI, loss_goal):
    if status != 'completed':
        return False
    elif (status == "compelted") \
        & (height is None) & (initial_weight is None) & (lowest_weight is None)\
        & (140<= height <= 200)&(18.5<= BMI <= 30)&(loss_goal < 0):
           return False
    else:
           return True

> progress_apply를 써서, 진행도를 바그래프 및 시간으로 정리하는 법
 >> from tqdm import tqdm
     tqdm.pandas 후에, progress_apply처리
     
     
> pivot table에 대하여 == pd.pivot_table(df, index = , values, columns , aggfunc = )
     : pd.pivot_table의 방법과 groupby()의 방법이 있습니다.
     : 전자는 모양, 후자는 속도에 강점이 있음.
     : pd.pivot_table 의 결과물 역시, DataFrame임.
      > 즉, 컬럼을 가공 및 결합하여, 다른 컬럼을 만들 수 있음 >> 그래서, Total이나, Conversion을 쉽게 구할 수 있음.
      > 다만, groupby와 섞어서 쓰면, 보다 쉽게 접근할 수 있을 것 같음
      >> 그래서, groupby 역시 친숙해지길.
      

> Concat에 대하여
     : concat은 행과 행의 결합 / 열과 열의 결합을 할 때 씀 ( concat( [t1,t2], axis = 1, join = ) #  axis 가 0이면 행(index니까), 1이면 컬럼
     : 이 때, 


> 전치행렬 T
     : 복수의 컬럼명(one hot encoding시)을 하나의 컬럼값으로 만드는 법!
     
      a = pd.pivot_table(good_coach, index = ['Status'], values = good_coach_coloumns,  aggfunc='sum', fill_value= 0)
      > a.T


> 데이터 타입에 대하여
: 날짜형  pd.to_date(df[''])

> 정렬에 대하여
: .sort(by = , ascending = True)


> 조건문 (apply)의 해결 노하우
: 하나하나 쪼개라
: 쪼갤 때마다, 가상의 예시로 적용해가며 정상 판단 여부를 확인하자

def test(df):
    if df["columns"] != "completed" :
      return True

dummy = {
        'Columns':'completed',
        'Age(clean)': 27,
        
    }
    
test(dumy) 를 실행, 결과값을 확인해봄.


> 그리고 week2 미션을 통해서 내가 배운 것들을 어떻게 정리하면 좋을까?
: 깃허브, 깃 그리고 노션으로의 정리 작업 시작

> duplicatae_drop(option = 'last'
: 더는 row_numbers() 먹혀서 작업하지 않아도 되는 즐거움
: 깃허브, 깃 그리고 노션으로의 정리 작업 시작

> 문자열 정제
: split 그리고 join
: split 후에 앞 혹은 뒤의 것만 선택하기 [0]

> lambda 활용
: (lambda x : return True if x 조건 else False) 

> 컬럼간 비교 True / Faslse
: a['TF'} = a['created_at'] > a['changed_at'] 
: True/False로 리턴

> 여러 조건 적용
: (df['a'] > b)|(df['c'] == d)

> solution으로부터 배울 것
: loc로 컬럼과 로우 지정하는 방법
 >> 멀티인덱서 xs 활용방법 : 피벗테이블에서 특정 열 지정에 편리
https://yganalyst.github.io/study/Pd_14/
https://pandas.pydata.org/docs/user_guide/reshaping.html

: for문을 이용해서, 반복된 컬럼명을 만드는 방법
: drop.na 활용
: apply 변형

> value_counts()를 정의하고, 이를 필터로 이용하는 방법
> merge의 연속
> dt.components 등의 시간 관련 정리

> 컬럼 정렬 
: .sort_index(axis = 1, ascending = True)


> 시각화 기본 옵션
: import matplotlib.pyplot as plt
: plt.figure(figsize = [20,5])

> 한 화면에 여러 시각화 만들기

평범!
figure, ((ax1,ax2,ax3),(bx1,bx2,bx3)) = plt.subplots(nrows = n, ncols = n')
figure.set_size_inches(18,3) --왜 = (a,b) 라고 생각했을까나.

sns.countplot(data = data, x = "성별코드", ax = ax1)
sns.countplot(data = data, x = "연령코드", ax = ax2) --> 요런 식으로 열을 지정해줄 수 있음 (행도 가능할까?)




컬럼간 간접적인 관계를 파악할 때!
figure, axes = plt.subplots(nrows = 3, ncols = 10)
axes = [3][1] 등으로 받아서 지정할 수 있음


> 판다스로 SQL - WHERE & IN 구현하기

: df['TF'] = df['col1'].apply(lambda x : x in df_2['col1'].unique(O)
: df[df['TF'] = True]


> 한글깨짐 / 선명하게 / minus 기호 깨짐 방지
:
import matplotlib
matplotlib.rc('font', family = 'NanumGothic')
matplotlib.rc('font', family = 'AppleGothic')

from Ipython.display import set_matplotlib_formats 

set_matplotlib_formats('retina')

matplotlib.rc('axe', unicode_minus = False)

> 사이즈 조절하기

import matplotlib.pyplot as plt

> 연령대
: 연령//10 

> apply의 각 행별 적용 (조건이 dataframe의 여러 컬럼에 걸쳐있을 때)
: df.apply(def, axis = 1) 로 지정
: def def(row):
  if row['col01'] == '의류' and row['연령대'] == '미입력':
     return True
  else:
     return row['연령대'] in str(row['age_y'])
     
  columns index
: df.iloc[:,:]

apply to rows as well as columns
>> apply (axis = 0, axis = 1)



